name: Update Feature Docs & LLM Context

on:
  # Runs after either deploy workflow completes on main
  workflow_run:
    workflows: ["Deploy API to Azure", "Deploy Frontend to Azure Static Web Apps"]
    types: [completed]
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write

jobs:
  regenerate-features:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: main
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Gather source inventory
        id: inventory
        run: |
          # Collect all source file contents into a single context file
          {
            echo "=== BACKEND CONTROLLERS ==="
            for f in src/AIDev.Api/AIDev.Api/Controllers/*.cs; do
              echo "--- $f ---"
              cat "$f"
              echo ""
            done

            echo "=== BACKEND SERVICES ==="
            for f in src/AIDev.Api/AIDev.Api/Services/*.cs; do
              echo "--- $f ---"
              cat "$f"
              echo ""
            done

            echo "=== BACKEND MODELS ==="
            for f in src/AIDev.Api/AIDev.Api/Models/*.cs src/AIDev.Api/AIDev.Api/Models/DTOs/*.cs; do
              echo "--- $f ---"
              cat "$f"
              echo ""
            done

            echo "=== FRONTEND COMPONENTS ==="
            for f in src/AIDev.Web/src/components/*.tsx; do
              echo "--- $f ---"
              cat "$f"
              echo ""
            done

            echo "=== FRONTEND SERVICES ==="
            for f in src/AIDev.Web/src/services/*.ts; do
              echo "--- $f ---"
              cat "$f"
              echo ""
            done

            echo "=== PROGRAM.CS ==="
            cat src/AIDev.Api/AIDev.Api/Program.cs

            echo "=== APPSETTINGS ==="
            cat src/AIDev.Api/AIDev.Api/appsettings.json
          } > /tmp/source-context.txt

          # Truncate if exceeding ~80K chars to stay within token limits
          head -c 80000 /tmp/source-context.txt > /tmp/source-context-trimmed.txt
          echo "chars=$(wc -c < /tmp/source-context-trimmed.txt)" >> "$GITHUB_OUTPUT"

      - name: Read current features doc
        id: current
        run: |
          if [ -f ApplicationFeatures.md ]; then
            echo "exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "exists=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Generate updated ApplicationFeatures.md via GitHub Models
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          python3 << 'PYSCRIPT'
          import json, subprocess, sys, os
          from datetime import date

          with open('/tmp/source-context-trimmed.txt') as f:
              source = f.read()

          payload = {
              "model": "gpt-4o",
              "temperature": 0.2,
              "max_tokens": 8000,
              "messages": [
                  {
                      "role": "system",
                      "content": (
                          "You are a technical writer for the AI Dev Pipeline product. "
                          "Generate a comprehensive ApplicationFeatures.md file that inventories ALL implemented features. "
                          "Use markdown tables organized by category. For each feature include: Feature name, Description, "
                          "Phase (Phase 1 = Structured Intake, Phase 2 = Product Owner Agent), and Status (âœ… Implemented or ðŸ”² Planned). "
                          "Include a summary table at the end. Be thorough â€” every endpoint, UI component, model, service, "
                          "and configuration should be catalogued. Include a 'Generated' date header. "
                          "Output ONLY the markdown content, no code fences."
                      )
                  },
                  {
                      "role": "user",
                      "content": f"Analyze the following source code and generate a complete ApplicationFeatures.md inventory. Today is {date.today().isoformat()}.\n\n{source}"
                  }
              ]
          }

          result = subprocess.run(
              ["curl", "-s", "-X", "POST",
               "https://models.inference.ai.github.com/chat/completions",
               "-H", "Content-Type: application/json",
               "-H", f"Authorization: Bearer {os.environ['GITHUB_TOKEN']}",
               "-d", json.dumps(payload)],
              capture_output=True, text=True
          )

          resp = json.loads(result.stdout)
          content = resp.get("choices", [{}])[0].get("message", {}).get("content", "")

          if not content:
              print("ERROR: No content in LLM response", file=sys.stderr)
              print(json.dumps(resp, indent=2), file=sys.stderr)
              sys.exit(1)

          with open("ApplicationFeatures.md", "w") as f:
              f.write(content)

          print(f"Generated ApplicationFeatures.md: {len(content)} chars")
          PYSCRIPT

      - name: Generate LLM-optimized .context files
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          python3 << 'PYSCRIPT'
          import json, subprocess, sys, os

          def generate_context_file(source_file, output_file, doc_type):
              """Read a human-readable .md and produce a compact .context version."""
              if not os.path.exists(source_file):
                  print(f"SKIP: {source_file} not found")
                  return

              with open(source_file) as f:
                  source = f.read()

              prompts = {
                  "objectives": (
                      "Compress the following product objectives document into a minimal-token format "
                      "optimized for LLM context injection (NOT human reading). Rules:\n"
                      "- Use pipe-delimited lines: CATEGORY|item|key details\n"
                      "- One line per objective, criterion, or principle\n"
                      "- Use abbreviations: auth=authentication, config=configuration, repo=repository, "
                      "req=request, impl=implementation, dev=development, mgmt=management\n"
                      "- Omit markdown formatting, headers, blank lines, prose\n"
                      "- Preserve ALL information â€” completeness is critical\n"
                      "- Start with a single header line: #OBJECTIVES|AI Dev Pipeline|<date>\n"
                      "- Target: under 1500 chars total"
                  ),
                  "salespack": (
                      "Compress the following product sales/marketing document into a minimal-token format "
                      "optimized for LLM context injection (NOT human reading). Rules:\n"
                      "- Use pipe-delimited lines: CATEGORY|item|key details\n"
                      "- One line per feature, benefit, differentiator, or pricing tier\n"
                      "- Use abbreviations: auth=authentication, config=configuration, repo=repository, "
                      "req=request, impl=implementation, dev=development, mgmt=management\n"
                      "- Omit markdown formatting, headers, blank lines, prose\n"
                      "- Preserve ALL information â€” completeness is critical\n"
                      "- Start with a single header line: #SALESPACK|AI Dev Pipeline|<date>\n"
                      "- Target: under 2000 chars total"
                  ),
                  "features": (
                      "Compress the following feature inventory into a minimal-token format "
                      "optimized for LLM context injection (NOT human reading). Rules:\n"
                      "- Use pipe-delimited lines: CATEGORY|feature_name|key details|status\n"
                      "- status: IMPL=implemented, PLAN=planned\n"
                      "- One line per feature â€” no sub-bullets, no descriptions longer than 15 words\n"
                      "- Use abbreviations: auth=authentication, config=configuration, repo=repository, "
                      "req=request, impl=implementation, dev=development, mgmt=management, "
                      "CRUD=create/read/update/delete, UI=user interface, API=api endpoint\n"
                      "- Omit markdown formatting, headers, blank lines, prose\n"
                      "- Every single feature MUST be listed â€” completeness is critical for duplicate detection\n"
                      "- Start with a single header line: #FEATURES|AI Dev Pipeline|<date>|<feature_count>\n"
                      "- Target: under 4000 chars total"
                  )
              }

              payload = {
                  "model": "gpt-4o",
                  "temperature": 0.1,
                  "max_tokens": 2000,
                  "messages": [
                      {"role": "system", "content": prompts[doc_type]},
                      {"role": "user", "content": source}
                  ]
              }

              result = subprocess.run(
                  ["curl", "-s", "-X", "POST",
                   "https://models.inference.ai.github.com/chat/completions",
                   "-H", "Content-Type: application/json",
                   "-H", f"Authorization: Bearer {os.environ['GITHUB_TOKEN']}",
                   "-d", json.dumps(payload)],
                  capture_output=True, text=True
              )

              resp = json.loads(result.stdout)
              content = resp.get("choices", [{}])[0].get("message", {}).get("content", "")

              if not content:
                  print(f"ERROR: No content for {output_file}", file=sys.stderr)
                  print(json.dumps(resp, indent=2), file=sys.stderr)
                  return

              with open(output_file, "w") as f:
                  f.write(content)

              print(f"Generated {output_file}: {len(content)} chars (from {len(source)} chars = {len(content)*100//len(source)}% of original)")

          generate_context_file("ApplicationObjectives.md", "ApplicationObjectives.context", "objectives")
          generate_context_file("ApplicationSalesPack.md",  "ApplicationSalesPack.context",  "salespack")
          generate_context_file("ApplicationFeatures.md",   "ApplicationFeatures.context",   "features")
          PYSCRIPT

      - name: Check for changes
        id: diff
        run: |
          git diff --quiet -- '*.md' '*.context' && echo "changed=false" >> "$GITHUB_OUTPUT" || echo "changed=true" >> "$GITHUB_OUTPUT"

      - name: Commit and push updated docs
        if: steps.diff.outputs.changed == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add ApplicationFeatures.md ApplicationObjectives.context ApplicationSalesPack.context ApplicationFeatures.context
          git commit -m "docs: auto-update feature docs and LLM context files after deploy

          Regenerated from current codebase via GitHub Models.
          [skip ci]"
          git push
